{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ZgquO3upKz"
      },
      "source": [
        "In this second practical session, we explore surface deformation algorithms with two applications : surface parametrization for texture mapping and as-rigid-as possible deformation for non-rigid alignment.\n",
        "\n",
        "Program for today:\n",
        "1. Surface Parameterisation\n",
        "\n",
        "    a. Tutte embedding,\n",
        "\n",
        "    b. Angle-preserving map with free boundary.\n",
        "    \n",
        "2. Surface alignment\n",
        "\n",
        "    a. Rigid alignment with Iterative Closest Point,\n",
        "\n",
        "    b. ARAP for non-rigid alignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_03tUwyupK2"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "We simplified the environment installation. Don't forget to comment after running this command once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Als8ZbZupK2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
            "'unzip' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "# !wget -q https://www.lix.polytechnique.fr/~pierson/cours/td2_utils.zip -O td2_utils.zip\n",
        "# !unzip -qqo td2_utils.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import requests, zipfile, io\n",
        "\n",
        "\n",
        "# url = \"https://www.lix.polytechnique.fr/~pierson/cours/td2_utils.zip\"\n",
        "# r = requests.get(url)\n",
        "\n",
        "# with open(\"td2_utils.zip\", \"wb\") as f:\n",
        "#     f.write(r.content)\n",
        "\n",
        "# with zipfile.ZipFile(\"td2_utils.zip\", \"r\") as zip_ref:\n",
        "#     zip_ref.extractall(\".\")  # \".\" = dossier courant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAKCnHSjupK3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/skoch9/meshplot/archive/0.4.0.tar.gz (from -r requirements.txt (line 12))\n",
            "  Using cached https://github.com/skoch9/meshplot/archive/0.4.0.tar.gz\n",
            "Collecting ipygany==0.5.0\n",
            "  Downloading ipygany-0.5.0-py2.py3-none-any.whl (2.9 MB)\n",
            "Requirement already satisfied: ipywidgets==8.1.7 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from -r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: nbformat==5.10.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from -r requirements.txt (line 3)) (5.10.4)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting matplotlib==3.7.4\n",
            "  Downloading matplotlib-3.7.4-cp310-cp310-win_amd64.whl (7.5 MB)\n",
            "Collecting networkx==3.1\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Collecting pyrender==0.1.45\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "Collecting shapely==2.0.2\n",
            "  Downloading shapely-2.0.2-cp310-cp310-win_amd64.whl (1.4 MB)\n",
            "Collecting vtk==9.3.0\n",
            "  Downloading vtk-9.3.0-cp310-cp310-win_amd64.whl (52.4 MB)\n",
            "Requirement already satisfied: pythreejs==2.4.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from -r requirements.txt (line 10)) (2.4.2)\n",
            "Collecting xvfbwrapper\n",
            "  Downloading xvfbwrapper-0.2.14-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: traittypes in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipygany==0.5.0->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipygany==0.5.0->-r requirements.txt (line 1)) (2.2.6)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipywidgets==8.1.7->-r requirements.txt (line 2)) (4.0.14)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipywidgets==8.1.7->-r requirements.txt (line 2)) (5.14.3)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipywidgets==8.1.7->-r requirements.txt (line 2)) (3.0.15)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipywidgets==8.1.7->-r requirements.txt (line 2)) (8.37.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.2.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbformat==5.10.4->-r requirements.txt (line 3)) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbformat==5.10.4->-r requirements.txt (line 3)) (5.8.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbformat==5.10.4->-r requirements.txt (line 3)) (2.21.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (0.12.1)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from matplotlib==3.7.4->-r requirements.txt (line 5)) (4.60.1)\n",
            "Collecting freetype-py\n",
            "  Downloading freetype_py-2.5.1-py3-none-win_amd64.whl (814 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from pyrender==0.1.45->-r requirements.txt (line 7)) (1.15.3)\n",
            "Requirement already satisfied: six in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from pyrender==0.1.45->-r requirements.txt (line 7)) (1.17.0)\n",
            "Collecting PyOpenGL==3.1.0\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.8.3-py3-none-any.whl (735 kB)\n",
            "Collecting pyglet>=1.4.10\n",
            "  Downloading pyglet-2.1.9-py3-none-any.whl (1.0 MB)\n",
            "Requirement already satisfied: ipydatawidgets>=1.1.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from pythreejs==2.4.2->-r requirements.txt (line 10)) (4.3.5)\n",
            "Requirement already satisfied: notebook in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter->-r requirements.txt (line 4)) (7.4.7)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter->-r requirements.txt (line 4)) (6.30.1)\n",
            "Requirement already satisfied: nbconvert in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter->-r requirements.txt (line 4)) (7.16.6)\n",
            "Requirement already satisfied: jupyterlab in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter->-r requirements.txt (line 4)) (4.4.9)\n",
            "Collecting jupyter-console\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (3.0.52)\n",
            "Requirement already satisfied: stack_data in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.6.3)\n",
            "Requirement already satisfied: decorator in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (5.2.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.19.2)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.8.5)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (0.27.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (2025.9.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat==5.10.4->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat==5.10.4->-r requirements.txt (line 3)) (311)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.2.14)\n",
            "Requirement already satisfied: tornado>=6.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (6.5.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (1.8.17)\n",
            "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (8.6.3)\n",
            "Requirement already satisfied: pyzmq>=25 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (27.1.0)\n",
            "Requirement already satisfied: psutil>=5.7 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (7.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (2.2.1)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (2.0.5)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (2.17.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (2.27.3)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: anyio in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (2025.8.3)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->jupyter->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.23.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (25.1.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (1.8.3)\n",
            "Requirement already satisfied: overrides>=5.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (7.7.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (25.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.1.1)\n",
            "Requirement already satisfied: isoduration in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: uri-template in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (24.11.1)\n",
            "Requirement already satisfied: fqdn in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.31 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 4)) (2.32.5)\n",
            "Requirement already satisfied: json5>=0.9.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: babel>=2.10 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 4)) (2.17.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.10.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: bleach[css]!=5.0.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (4.14.2)\n",
            "Requirement already satisfied: webencodings in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 4)) (2.23)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from isoduration->jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema>=2.6->nbformat==5.10.4->-r requirements.txt (line 3)) (2.9.0.20250822)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (0.2.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\alexa\\graphprocess\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r requirements.txt (line 2)) (3.0.0)\n",
            "Using legacy 'setup.py install' for PyOpenGL, since package 'wheel' is not installed.\n",
            "Installing collected packages: numpy, trimesh, PyOpenGL, pyglet, networkx, matplotlib, jupyter-console, imageio, freetype-py, xvfbwrapper, vtk, shapely, pyrender, jupyter, ipygany\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "    Running setup.py install for PyOpenGL: started\n",
            "    Running setup.py install for PyOpenGL: still running...\n",
            "    Running setup.py install for PyOpenGL: finished with status 'done'\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.6\n",
            "    Uninstalling matplotlib-3.10.6:\n",
            "      Successfully uninstalled matplotlib-3.10.6\n",
            "Successfully installed PyOpenGL-3.1.0 freetype-py-2.5.1 imageio-2.37.0 ipygany-0.5.0 jupyter-1.1.1 jupyter-console-6.6.3 matplotlib-3.7.4 networkx-3.1 numpy-1.26.4 pyglet-2.1.9 pyrender-0.1.45 shapely-2.0.2 trimesh-4.8.3 vtk-9.3.0 xvfbwrapper-0.2.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\alexa\\graphprocess\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eDQeeRcdupK4"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "xvfbwrapper is not supported on this platform: Windows",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\alexa\\graphprocess\\lib\\site-packages\\xvfbwrapper.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfcntl\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fcntl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csc_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# THE FOLLOWING COME FROM THE PROVIDED DATA, DO NOT TRY TO PIP INSTALL THEM\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplot_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplu\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmesh_utils\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmesh_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TriMesh\n",
            "File \u001b[1;32mc:\\Users\\alexa\\Downloads\\Geometry processing\\TD2\\plot_utils\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeshplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyrender\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvtk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\alexa\\Downloads\\Geometry processing\\TD2\\plot_utils\\vtk.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplot_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvtkviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvtkVisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VTKSurface, VTKPointCloudSphere, VTKVisualization, center_mesh_give_size\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageFont, ImageDraw\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxvfbwrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Xvfb\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrimesh\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcm\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\alexa\\graphprocess\\lib\\site-packages\\xvfbwrapper.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     system \u001b[38;5;241m=\u001b[39m platform\u001b[38;5;241m.\u001b[39msystem()\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxvfbwrapper is not supported on this platform: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mXvfb\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Maximum value to use for a display. 32-bit maxint is the\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# highest Xvfb currently supports\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: xvfbwrapper is not supported on this platform: Windows"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse.linalg as sla\n",
        "import scipy.sparse\n",
        "from scipy.sparse import csc_matrix\n",
        "\n",
        "# THE FOLLOWING COME FROM THE PROVIDED DATA, DO NOT TRY TO PIP INSTALL THEM\n",
        "import plot_utils as plu\n",
        "import mesh_utils\n",
        "from mesh_utils.mesh import TriMesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aqEoYb_upK4"
      },
      "source": [
        "### Choose your rendering backend.\n",
        "\n",
        "Main settings: <b><code style=\"color:red;\">colab</code></b> is if you are in colab, <b><code style=\"color:red;\">server</code></b> if you use a cluster (always true when using colab). The latter needs to have the `xvfb` package installed (automatic in colab). Set up the values correctly!\n",
        "\n",
        "For those struggling with meshplot, use <b><code style=\"color:red;\">meshplot=False</code></b>\n",
        "\n",
        "You shouldn't have any problems anymore. However, the interactive windows are replaced by rendering (in different views) of the meshes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt52r2GzupK4"
      },
      "outputs": [],
      "source": [
        "colab = False\n",
        "server = True\n",
        "if colab:\n",
        "    server=True\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "if server:\n",
        "    from xvfbwrapper import Xvfb\n",
        "    display = Xvfb(width=1280, height=740, colordepth=16)\n",
        "    display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiOgqY98upK4"
      },
      "outputs": [],
      "source": [
        "meshplot = False\n",
        "if meshplot:\n",
        "    renderer = plu.MeshPlotRenderer\n",
        "else:\n",
        "    renderer = plu.vtkRenderer\n",
        "vtkrenderer = plu.vtkRenderer\n",
        "mprenderer = plu.MeshPlotRenderer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt4bqPXgupK5"
      },
      "source": [
        "# 1 - Surface Parameterisation\n",
        "\n",
        "Given a triangle mesh with triangle list $T$ ($n_f \\times 3$ array of integers) and vertex coordinates $X$ ($n_v \\times 3$ array of floats), a parametrization is simply an assignment of planar coordinates $U$ ($n_v \\times 2$ array of floats) for each vertex of the mesh. This parametrization will be vizualized by mapping a texture in planar coordinates to 3D coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qESu4pERupK5"
      },
      "source": [
        "## 1.1 Tutte embedding\n",
        "\n",
        "The most simple way of computing planar coordinates is to fix the boundary of the mesh to predefined positions (in this example a rectangle) and place the inner vertices at the barycenter of their neighbours. More precisely, the planar coordinates $(u_i,v_i)$ of vertex $i$ satisfies the equation:\n",
        "$$ \\sum_{j \\in N_i} w_{ij} (u_j - u_i) = 0, \\quad \\sum_{j \\in N_i} w_{ij} (v_j - v_i) = 0, $$\n",
        "where $w_{ij}$ are the cotan-weights computed in the previous practical session and $N_i$ is the set of vertices linked to $i$ by an edge. Moreover, for a boundary vertex $j$, the coordinates $(u_j,v_j)$ are constrained to the position $(\\bar{u}_j,\\bar{v}_j)$.\n",
        "\n",
        "This system of linear equations can be easily rewritten in term of Laplacian matrix $W$ computed in the previous session:\n",
        "$$\n",
        "\\begin{array}{l}\n",
        "W u = 0, \\text{ and } W v = 0, \\\\\n",
        "u_j = \\bar{u}_j, \\text{ and } v_j = \\bar{v}_j \\text{ for all boundary vertex $j$.}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Let `id_int` and `id_bnd` be the lists of interior and boundary indices. The boundary coordinates `u[id_bnd]` and `v[id_bnd]` are given by the function ???.  By linearity, the constrained system reads `W[id_int,id_int]*u[id_int] =-W[id_int,id_bnd]*u[id_bnd]`.\n",
        "\n",
        "1. Build the lists `id_int` and `id_bnd`\n",
        "2. Solve the constrained system of linear equations\n",
        "3. Vizualize the texture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U07wxp8upK5"
      },
      "source": [
        "###  QUESTION 1 - Border Edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "245puRCuupK5"
      },
      "source": [
        "**Given a set of triangles, compute the list of (unordered) edges which lie at the border**\n",
        "\n",
        "Note that we use np.unique in the next cell, so don't overcomplicate the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofWyjZWkupK5"
      },
      "outputs": [],
      "source": [
        "def get_border_edges(triangles):\n",
        "    \"\"\"\n",
        "    Get the border edges of a mesh. In no particular order\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    triangles : ndarray of shape (n_triangles, 3)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    border_edges : list of list of length n_border_edges.\n",
        "                   The border edges of the mesh. Element i contains the two\n",
        "                     vertices of the i-th border edge.\n",
        "    \"\"\"\n",
        "    return border_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztcrLHVxupK5"
      },
      "outputs": [],
      "source": [
        "mesh1 = TriMesh('./data/sphere_cut_uv.obj').process(k=0)\n",
        "\n",
        "border_edges = get_border_edges(mesh1.faces)\n",
        "# Visualize the border. It is here just a cut of the sphere\n",
        "renderer.plot(mesh1, points=np.unique(border_edges))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyX_PInfupK5"
      },
      "source": [
        "### Question 2 - Orderd points on a circle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZB3v-WfupK5"
      },
      "source": [
        "**Write a function to generate evenly spaced points on the circle**\n",
        "These are going to be the fixed positions of our border vertices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Izedw93XupK6"
      },
      "outputs": [],
      "source": [
        "def get_n_points_on_circle(n_points):\n",
        "    \"\"\"\n",
        "    Builds n_points evenly spaced points on the unit circle.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_points : int\n",
        "        Number of points to generate\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    points : ndarray of shape (n_points, 2)\n",
        "        The points on the unit circle\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    return points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p8sN_zzupK6"
      },
      "outputs": [],
      "source": [
        "circle_points = get_n_points_on_circle(10)\n",
        "plt.figure(dpi=100)\n",
        "plt.scatter(circle_points[:,0], circle_points[:,1])\n",
        "plt.axis('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DhVl-gqupK6"
      },
      "source": [
        "### Question 3 - Solving the Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHnCL_0supK6"
      },
      "source": [
        "**Solve for the uv coordinate using ```scipy.sparse.linalg.spsolve```**\n",
        "\n",
        "Tip: To select ```W[id_int,id_int]``` on a sparse matrix ```W[id_int,id_int]```, use ```W[id_int,:][:,id_int]```.\n",
        "\n",
        "Because your border points are *ordered*, you will need to use an *ordered* list if border edges. We provide a function below which generates an *ordered* list of border edges using your ```get_border_edges``` function from Question 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vxiq_qAHupK6"
      },
      "outputs": [],
      "source": [
        "def find_next_edge(current_edge, remaining_edges):\n",
        "        for i, edge in enumerate(remaining_edges):\n",
        "            if current_edge[1] in edge:\n",
        "                return i, edge #if edge[0]==current_edge[1] else edge[::-1]\n",
        "        return None, None\n",
        "\n",
        "def build_ordered_edges(triangles):\n",
        "    \"\"\"\n",
        "    Compute an ordered list of edges that form a path around the border of the mesh.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    triangles : ndarray of shape (n_triangles, 3)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ordered_edge_list : list of list of length n_border_edges.\n",
        "                        The border edges of the mesh. Element i contains the two\n",
        "                        vertices of the i-th border edge.\n",
        "    \"\"\"\n",
        "    ordered_edge_list=[]\n",
        "\n",
        "    current_edge=border_edges[0]\n",
        "    remaining_edges=border_edges[1:]\n",
        "\n",
        "    #on part maintenant d'une extremité pour arriver à l'autre extrémité et donc oublier aucune arrête\n",
        "    while True:\n",
        "\n",
        "        ordered_edge_list.append(current_edge)\n",
        "        i, current_edge = find_next_edge(current_edge, remaining_edges)\n",
        "        if i==None:\n",
        "            break\n",
        "        del(remaining_edges[i])\n",
        "    print(len(ordered_edge_list)==len(border_edges))\n",
        "\n",
        "    return ordered_edge_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJD6H0k1upK6"
      },
      "outputs": [],
      "source": [
        "# Load the mesh and compute the Laplacian\n",
        "mesh1 = TriMesh('./data/sphere_cut_uv.obj').process(k=0)\n",
        "uv_map = mesh_utils.read_obj_texture('./data/sphere_cut_uv.obj')[-1]\n",
        "# Get the list of ordered edges and the Laplacian\n",
        "ordered_edges = build_ordered_edges(mesh1.faces)\n",
        "W = mesh1.W\n",
        "\n",
        "renderer.plot_texture(mesh1.vertices, mesh1.faces, uv_map, wireframe=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai6jlL8WupK6"
      },
      "outputs": [],
      "source": [
        " #TODO Compute the embedding u,v using the text above.\n",
        "\n",
        "ordered_edges = build_ordered_edges(mesh1.faces)\n",
        "\n",
        "# 1. Identify boundary and interior vertex indices\n",
        "id_bnd = [edge[0] for edge in ordered_edges]\n",
        "id_int = [i for i in range(mesh1.n_vertices) if i not in id_bnd]\n",
        "\n",
        "# 2. Generate boundary coordinates on the unit circle (ordered)\n",
        "u_border = get_n_points_on_circle(len(id_bnd))\n",
        "\n",
        "# 3. Initialize arrays for all UV coordinates\n",
        "uv_total = np.zeros((mesh1.n_vertices, 2))\n",
        "uv_total[id_bnd] = u_border\n",
        "\n",
        "# 4. Solve the constrained linear system for interior vertices\n",
        "# For each coordinate (u and v), solve W_ii * u_int = -W_ib * u_bnd\n",
        "W = mesh1.W\n",
        "W_ii = W[id_int, :][:, id_int]\n",
        "W_ib = W[id_int, :][:, id_bnd]\n",
        "\n",
        "# Solve for u and v separately\n",
        "u_int = sla.spsolve(W_ii, -W_ib @ u_border[:, 0])\n",
        "v_int = sla.spsolve(W_ii, -W_ib @ u_border[:, 1])\n",
        "\n",
        "# 5. Fill in the interior UV coordinates\n",
        "uv_total[id_int, 0] = u_int\n",
        "uv_total[id_int, 1] = v_int\n",
        "\n",
        "# For compatibility with the rest of the notebook\n",
        "uv_int = uv_total[id_int]\n",
        "uv_int = ### (n,2) computed UV coordinates (takes more than 1 line)\n",
        "\n",
        "uv_total = ### (n,2) computed UV coordinates (takes more than 1 line)\n",
        "\n",
        "flat_coords =  np.zeros((mesh1.n_vertices,3))\n",
        "flat_coords[:,:2] = uv_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0otce3VupK6"
      },
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "# Flattened coordinates with regular grid\n",
        "renderer.plot_texture(flat_coords, mesh1.faces, uv_total, wireframe=False, multiple_sides=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxIDRE2yupK6"
      },
      "outputs": [],
      "source": [
        "# We can take the regular grid back to the sphere\n",
        "renderer.plot_texture(mesh1.vertices, mesh1.faces, uv_map, wireframe=True)\n",
        "\n",
        "# Or take the Texture of the sphere to the flat world\n",
        "# renderer.plot_texture(flat_coords, mesh1.faces, uv_total, wireframe=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zco9uKtPupK6"
      },
      "source": [
        "Let's now visualize how it would render on the Earth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nd-665JMupK6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/earth_daymap.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "image = plt.imread('data/earth_daymap.jpg')\n",
        "plt.figure(dpi=120)\n",
        "plt.imshow(image)\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d39aFOX7upK6"
      },
      "outputs": [],
      "source": [
        "vtkrenderer.plot_texture(mesh1.vertices, mesh1.faces, uv_map, texture_img=\"data/earth_daymap.jpg\", wireframe=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuCmAP3upK6"
      },
      "source": [
        "### If you want to visualize it better, save it and load in Meshlab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbxdmzb_upK6"
      },
      "outputs": [],
      "source": [
        "os.makedirs('results', exist_ok=True)\n",
        "shutil.copyfile('data/earth_daymap.jpg', 'results/earth_daymap.jpg')\n",
        "\n",
        "\n",
        "# THIS EXPORTS A .OBJ FILE WITH TEXTURE AND MATERIAL INFORMATION. DOWNLOAD AND OPEN WITH MESHLAB\n",
        "TriMesh(flat_coords, mesh1.faces).export_texture('results/tutte_earth.obj', uv_map, texture_im='earth_daymap.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXavsSJUupK7"
      },
      "source": [
        "## 1.2 Least Square Conformal Map\n",
        "\n",
        "Conformal maps are special type of parametrization which preserves angles and circles. On a smooth surface, they are characterized by the relationship between the gradient of the coordinate $u$ and the coordinate $v$\n",
        "$$ \\nabla u = n \\times \\nabla v $$\n",
        "where $n$ is the surface normal. On a triangle mesh, the coordinates $(u,v)$ are computed using a linear least-squares problem\n",
        "$$ \\min_{u,v} \\sum_{t \\in T} A_t |\\nabla u - n \\times \\nabla v|^2 \\text{ subject to the constraint: } \\sum_i u_i^2 + v_i^2 = 1 $$\n",
        "where $A_t$ is the area of triangle $t$. As explained in the course, the objective function can be written in term of the Laplacian matrix $W$. This leads to the smallest eigenvalue problem\n",
        "$$ \\min_{u,v} \\begin{pmatrix} u \\\\ v \\end{pmatrix}^\\top \\begin{pmatrix} W & -M \\\\ -M^\\top & W \\end{pmatrix} \\begin{pmatrix} u & v \\end{pmatrix} \\text{ subject to the constraint: } \\sum_i u_i^2 + v_i^2 = 1 $$\n",
        "The sparse matrix $M$ of size $n_v \\times n_v$ is given by\n",
        "$$ M_{ij} = \\begin{array}{ll}\n",
        "0 & \\text{if $i$ or $j$ is an interior vertex } \\\\\n",
        "1/2 & \\text{if $i$ to $j$ is a positive edge of the boundary triangle} \\\\\n",
        "-1/2 & \\text{if $i$ to $j$ is a negative edge of the boundary triangle}\n",
        "\\end{array} $$\n",
        "\n",
        "Positive edges are edges that appear when going around a face in the order provided in the file. Negative edges are when going the opposite direction.\n",
        "\n",
        "*Tips:* To assemble this matrix simply accumulate $\\pm\\frac{1}{2}$ values for all triangles using the triangle list using the formula above. Since interior edges appear twice in opposite direction in the mesh, their coefficient will vanish for them, and only values for border edges will remin\n",
        "\n",
        "\n",
        "1. Build the sparse matrix `M`\n",
        "2. Compute the LSCM parametrization using `scipy.sparse.linalg.eigs`\n",
        "3. Extract the boundary coordinate of the parametrization and use them to compute a Tutte embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy6O8Xs3upK7"
      },
      "source": [
        "### Question 4 - Build M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzup4589upK7"
      },
      "outputs": [],
      "source": [
        "def build_M(faces):\n",
        "    \"\"\"\n",
        "    Build the M matrix above with values only at border edges.\n",
        "    M can be build by adding the formula for M_ij for each edge of each face on the mesh.\n",
        "    Coefficients at interior edges will vanish because they appear twice with opposite signs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    faces : ndarray of shape (n_faces, 3)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    M : scipy.sparse.csr_matrix of shape (n_vertices, n_vertices)\n",
        "    \"\"\"\n",
        "    n_vertices = faces.max() + 1\n",
        "    row = []\n",
        "    col = []\n",
        "    data = []\n",
        "\n",
        "    # For each face, add +/- 0.5 to the corresponding entries\n",
        "    for tri in faces:\n",
        "        # edges: (i,j), (j,k), (k,i)\n",
        "        i, j, k = tri\n",
        "        # (i, j)\n",
        "        row.append(i)\n",
        "        col.append(j)\n",
        "        data.append(0.5)\n",
        "        row.append(j)\n",
        "        col.append(i)\n",
        "        data.append(-0.5)\n",
        "        # (j, k)\n",
        "        row.append(j)\n",
        "        col.append(k)\n",
        "        data.append(0.5)\n",
        "        row.append(k)\n",
        "        col.append(j)\n",
        "        data.append(-0.5)\n",
        "        # (k, i)\n",
        "        row.append(k)\n",
        "        col.append(i)\n",
        "        data.append(0.5)\n",
        "        row.append(i)\n",
        "        col.append(k)\n",
        "        data.append(-0.5)\n",
        "\n",
        "    M = scipy.sparse.csr_matrix((data, (row, col)), shape=(n_vertices, n_vertices))\n",
        "    return M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU7awdyEupK7"
      },
      "source": [
        "### Question 5 - Solve the system\n",
        "\n",
        "Use scipy [bmat function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bmat.html) to build sparse matrices from blocks.\n",
        "Use scipy\n",
        "\n",
        "Try with the two meshes (diablo doesn't have uv map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O5_SZ11upK7"
      },
      "outputs": [],
      "source": [
        "#mesh1 = TriMesh(\"./data/diablo_cut2.obj\").process(k=0)\n",
        "mesh1 = TriMesh(\"./data/sphere_cut_uv.obj\").process(k=0)\n",
        "uv_map = v,f,uv_map = mesh_utils.read_obj_texture('./data/sphere_cut_uv.obj')\n",
        "W = mesh1.W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6DneUJoupK7"
      },
      "outputs": [],
      "source": [
        "M = build_M(mesh1.faces)\n",
        "# No additional code is needed here; you can proceed directly to building the system_matrix.\n",
        "system_matrix = scipy.sparse.bmat([[W, -M], [-M.transpose(), W]], format='csr') #TODO#TODO\n",
        "\n",
        "res_eigenvalues, res_eigenvectors = scipy.sparse.linalg.eigsh(system_matrix, k=3, which='LM', sigma=-0.001)\n",
        "\n",
        "# Only take the real part\n",
        "\n",
        "res_eigenvectors = res_eigenvectors.real\n",
        "\n",
        "# Check that first 2 eigenvalues are 0\n",
        "print(res_eigenvalues)\n",
        "# Visualize the eigenvectors as UV coordinates (skip the first eigenvector, which is constant)# Visualize the eigenvectors as UV coordinates (skip the first eigenvector, which is constant)# Visualize the eigenvectors as UV coordinates\n",
        "uv_coords = res_eigenvectors[:, 1:3].reshape((mesh1.n_vertices, 2), order='F')\n",
        "#valeurs proche de 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC7hPOTqupK7"
      },
      "outputs": [],
      "source": [
        "uv_coords = res_eigenvectors[:,2].reshape((mesh1.n_vertices,2), order='F')\n",
        "\n",
        "renderer.plot_texture(mesh1.vertices, mesh1.faces, uv_coords)\n",
        "\n",
        "#plu.plot_texture(flat_coords, mesh1.faces, flat_coords)\n",
        "\n",
        "\n",
        "# For the Sphere\n",
        "#plu.plot_texture(flat_coords, mesh1.faces, uv_map, wireframe=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AngOcI43upK7"
      },
      "source": [
        "you can again visualize with the earth map on the sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNsOVYJ1upK7"
      },
      "outputs": [],
      "source": [
        "vtkrenderer.plot_texture(mesh1.vertices, mesh1.faces, uv_coords, texture_img=\"data/earth_daymap.jpg\", wireframe=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR_TrkowupLA"
      },
      "outputs": [],
      "source": [
        "flat_coords =  np.zeros((mesh1.n_vertices,3))\n",
        "flat_coords[:,:2] = uv_total\n",
        "TriMesh(flat_coords, mesh1.faces).export_texture('results/lscm_earth.obj', uv_coords, texture_im='earth_daymap.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULvroCLjupLA"
      },
      "source": [
        "###  Question 6 - Extract the Border and compute the tutte embedding on the same border (with ordering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MJBghuBpupLA"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1418130980.py, line 20)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    uv_int = ### (n,2) computed UV coordinates (takes more than 1 line)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "id_bnd = [edg[0] for edg in ordered_edges]\n",
        "# Ici, on veut imposer comme frontière les coordonnées UV extraites de la LSCM (uv_coords) pour les sommets de bord.\n",
        "# id_bnd contient les indices des sommets de bord dans l'ordre, donc on peut simplement faire :\n",
        "u_border = uv_coords[id_bnd]\n",
        "\n",
        "# On résout le système linéaire comme dans la question 3, mais avec cette nouvelle frontière\n",
        "uv_tutte_2 = np.zeros((mesh1.n_vertices, 2))\n",
        "uv_tutte_2[id_bnd] = u_border\n",
        "\n",
        "id_int = [i for i in range(mesh1.n_vertices) if i not in id_bnd]\n",
        "W_ii = W[id_int, :][:, id_int]\n",
        "W_ib = W[id_int, :][:, id_bnd]\n",
        "\n",
        "u_int = sla.spsolve(W_ii, -W_ib @ u_border[:, 0])\n",
        "v_int = sla.spsolve(W_ii, -W_ib @ u_border[:, 1])\n",
        "\n",
        "uv_tutte_2[id_int, 0] = u_int\n",
        "uv_tutte_2[id_int, 1] = v_int\n",
        "\n",
        "uv_int = ### (n,2) computed UV coordinates (takes more than 1 line)\n",
        "uv_tutte_2 =\n",
        "\n",
        "flat_coords = np.zeros((mesh1.n_vertices,3))\n",
        "flat_coords[:,:2] = uv_tutte_2\n",
        "print(np.linalg.norm(uv_tutte_2 - uv_coords))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBbEXTNAupLA"
      },
      "outputs": [],
      "source": [
        "plt.plot(u_border[:, 0], u_border[:, 1]) # Just a check: we plot to verify that the border is continuous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RXwCFrjupLA"
      },
      "outputs": [],
      "source": [
        "renderer.plot_texture(flat_coords, mesh1.faces, uv_tutte_2, wireframe=True, multiple_sides=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAmrmFT7upLA"
      },
      "outputs": [],
      "source": [
        "vtkrenderer.plot_texture(mesh1.vertices, mesh1.faces, uv_tutte_2, wireframe=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmK7QHgEupLA"
      },
      "source": [
        "# 2 Surface Alignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbFxqBmOupLA"
      },
      "source": [
        "## 2.1 Iterative Closest Point\n",
        "\n",
        "The goal of this algorithm is to align two point clouds $X = \\{ x_i \\}$ and $Y = \\{ y_i \\}$ using only rigid transformations -- translation and rotation. It is standard algorithm to align 3D scans taken from different viewpoints. The most basic implementation iterates between three steps until convergence:\n",
        "\n",
        "1. For each point of $X$ compute the closest point in the set $Y$. This assignment is given by the table $p$\n",
        "$$ p_i = \\arg\\min_{j} \\|x_i - y_j\\|^2 .$$\n",
        "This can be done efficiently with a knn-search.\n",
        "\n",
        "2. Find the translation that best align the point cloud given the assignment $p$\n",
        "$$ \\min_{t \\in \\mathbb{R}^3} \\sum_i \\|x_i + t - y_{p_i}\\|^2 .$$\n",
        "This problem can be solved exactly with the formula $t = \\frac{1}{|X|}\\sum_i y_i - x_i$.\n",
        "\n",
        "3. Compute the rotation aligning the point cloud after translation:\n",
        "$$ \\min_{R} \\sum_i \\|Rx_i + t - y_{p_i}\\|^2 .$$\n",
        "This is an [orthogonal Procrustes problem](https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem) and can be solved efficiently using a Singular Value Decomposition ([SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition)). Let the matrix $A = \\sum_i (t-y_{p_i})x_i^\\top$ be decomposed as $A = U S V^\\top$ where $U,V$ are unitary matrices and $S$ a diagonal matrix. The optimal rotation is given by $R = U D V^\\top$ with $D$ a diagonal matrix with $+1$ on the diagonal corresponding to the two largest singular values and $\\pm 1$ on the smallest singular value. The sign is chosen so that $\\det R = 1$.\n",
        "\n",
        "4. Update the position of $X$: $x_i \\leftarrow Rx_i+t$\n",
        "\n",
        "\n",
        "**To do:**\n",
        "1. Implement the steps\n",
        "2. Align the Armadilo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr8yol14upLA"
      },
      "source": [
        "### Question 7 - Compute Nearest Neighbor\n",
        "\n",
        "To speed up computation, use `scipy.spatial.cKDTree`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C5ZbbfVBupLA"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import cKDTree\n",
        "\n",
        "def compute_nearest_neighbor(X, Y):\n",
        "    \"\"\"\n",
        "    Compute the nearest neighbor in Y for each point in X\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : (n, d) array of points\n",
        "    Y : (m, d) array of points\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    nearst_neighbor : (n,) array of indices of the nearest neighbor in Y for X\n",
        "    \"\"\"\n",
        "    # TODO DO NOT USE LOOPS\n",
        "    tree = cKDTree(Y)\n",
        "    _, nearest_neighbor = tree.query(X, k=1)\n",
        "    return nearest_neighbor\n",
        "    _, nearest_neighbor = tree.query(X, k=1)\n",
        "    querier = KNNSearch(X)\n",
        "    nn_indices = querier.query(Y, 1)\n",
        "    return nn_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0SwyQN0upLA"
      },
      "source": [
        "### Question 8 - Compute optimal rotations and translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On veut trouver $(R, t)$ qui minimise\n",
        "$ E(R, t) = \\sum_{i=1}^n \\| R x_i + t - y_i \\|^2 $\n",
        "\n",
        "sous la contrainte $ R^\\top R = I $\n",
        "\n",
        "1. Élimination de la translation :\n",
        "\n",
        "Les barycentres sont :\n",
        "$\n",
        "\\mu_X = \\frac{1}{n}\\sum_{i=1}^n x_i, \\quad \n",
        "\\mu_Y = \\frac{1}{n}\\sum_{i=1}^n y_i. $ \n",
        "\n",
        "En posant les points centrés :\n",
        "$\n",
        "\\tilde{x}_i = x_i - \\mu_X,\n",
        "\\tilde{y}_i = y_i - \\mu_Y,\n",
        "$\n",
        "la translation optimale pour un R donné est :\n",
        "$\n",
        "t = \\mu_Y - R \\mu_X.\n",
        "$\n",
        "\n",
        "2. Réduction du problème à la rotation :\n",
        "\n",
        "On obtient donc :\n",
        "$\n",
        "E(R) = \\sum_{i=1}^n \\| R \\tilde{x}_i - \\tilde{y}_i \\|^2.\n",
        "$\n",
        "\n",
        "Si on développe :\n",
        "$\n",
        "E(R) = \\sum_i (\\| \\tilde{x}_i \\|^2 + \\| \\tilde{y}_i \\|^2) - 2 \\operatorname{trace}(R H)\n",
        "$\n",
        "où :\n",
        "$\n",
        "H = \\sum_i \\tilde{x}_i \\tilde{y}_i^\\top.\n",
        "$\n",
        "\n",
        "Minimiser E(R) revient donc à maximiser :\n",
        "$ \\operatorname{trace}(R H) $ pour $R \\in O(d)$\n",
        "\n",
        "\n",
        "3. Décomposition SVD :\n",
        "\n",
        "On applique donc la SVD à H :\n",
        "$\n",
        "H = U \\Sigma V^\\top\n",
        "$\n",
        "avec U, V  orthogonales et $ \\Sigma = \\operatorname{diag}(\\sigma_1, \\dots, \\sigma_d) $\n",
        "\n",
        "Alors :\n",
        "$\n",
        "\\operatorname{trace}(R H) = \\operatorname{trace}(V^\\top R U \\Sigma).\n",
        "$\n",
        "Posons $ Q = V^\\top R U $ (orthogonale comme produit de matrice orthogonale), donc :\n",
        "$\n",
        "\\operatorname{trace}(R H) = \\sum_i \\sigma_i Q_{ii}.\n",
        "$\n",
        "\n",
        "Par l’inégalité de von Neumann :\n",
        "$\n",
        "\\operatorname{trace}(R H) \\le \\sum_i \\sigma_i,\n",
        "$\n",
        "avec égalité si Q = I\n",
        "\n",
        "Donc :\n",
        "$\n",
        "\\underline{R = V U^\\top}.\n",
        "$\n",
        "\n",
        "4. Correction de la réflexion :\n",
        "Si $\\det(R) < 0 $, on force une rotation propre en posant :\n",
        "$\n",
        "D = \\operatorname{diag}(1, \\dots, 1, \\det(V U^\\top))\n",
        "R = V D U^\\top.\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM1hDpA8upLB"
      },
      "outputs": [],
      "source": [
        "def compute_rigid_transform(X_source, X_target):\n",
        "    \"\"\"\n",
        "    Compute the optimal rotation matrix and translation that aligns two point clouds of the same size X_source and X_target.\n",
        "    This rotation should be applied to X_source.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_source : (n, d) array of points\n",
        "    Y_target : (n, d) array of points\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    R : (d, d) rotation matrix\n",
        "    t : (d,) translation vector\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    #On utilise la méthode SVD\n",
        "\n",
        "    # On centre les deux nuages de points pour ignorer la translation\n",
        "    mu_X = np.mean(X_source, axis=0)\n",
        "    mu_Y = np.mean(X_target, axis=0)\n",
        "\n",
        "    X_centered = X_source - mu_X\n",
        "    Y_centered = X_target - mu_Y\n",
        "\n",
        "    # Matrice de covariance\n",
        "    H = X_centered.T @ Y_centered\n",
        "\n",
        "    # Décomposition en valeurs singulières\n",
        "    U, S, Vt = np.linalg.svd(H)\n",
        "\n",
        "    # Calcul de la rotation optimale\n",
        "    R = Vt.T @ U.T\n",
        "\n",
        "    # Correction si réflexion\n",
        "    if np.linalg.det(R) < 0:\n",
        "        Vt[-1, :] *= -1\n",
        "        R = Vt.T @ U.T\n",
        "\n",
        "    # Calcul de la translation pour terminer\n",
        "    t = mu_Y - R @ mu_X\n",
        "    \n",
        "    return R, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77hME9LupLB"
      },
      "source": [
        "### Question 9 - Apply the ICP algorithm\n",
        "We provide a function to apply a rigid transformation ```R,t``` to a point cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MwwpcPzXupLB"
      },
      "outputs": [],
      "source": [
        "def transform_pointcloud(X,R,t):\n",
        "    \"\"\"\n",
        "    Transform a point cloud X by a rotation matrix R and a translation vector t.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : (n, d) array of points\n",
        "    R : (d, d) rotation matrix\n",
        "    t : (d,) translation vector\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X_transformed : (n, d) array of transformed points\n",
        "    \"\"\"\n",
        "    return X @ R.T + t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbgaEQnbupLB"
      },
      "outputs": [],
      "source": [
        "def icp_align(X_source, Y_target, n_iter=10):\n",
        "    \"\"\"\n",
        "    Align two point clouds X_source and Y_target using the ICP algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_source : (n, d) array of points\n",
        "    Y_target : (m, d) array of points\n",
        "    n_iter   : int - number of iterations of the ICP algorithm\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X_aligned : (n, d) array of aligned points\n",
        "    \"\"\"\n",
        "    X_aligned = X_source.copy()\n",
        "    for i in range(n_iter):\n",
        "        nn_indices = compute_nearest_neighbor(X_aligned, Y_target)\n",
        "        Y_nn = Y_target[nn_indices]\n",
        "        R, t = compute_rigid_transform(X_aligned, Y_nn)\n",
        "        X_aligned = transform_pointcloud(X_aligned, R, t)\n",
        "    return X_aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq1N0abbupLB"
      },
      "outputs": [],
      "source": [
        "def plot_superimposed(mesh1, mesh2, color_1=[139, 0, 139], color_2=[210, 105, 30], *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Plot the superposition of the two meshes\n",
        "    \"\"\"\n",
        "    #2B7FFF#2B7FFF\n",
        "    if meshplot:\n",
        "        cmap_1 = np.ones(mesh1.vertices.shape)*np.array(color_1)/255.\n",
        "        cmap_2 = np.ones(mesh2.vertices.shape)*np.array(color_2)/255.\n",
        "    else:\n",
        "        cmap_1 = np.ones(mesh1.vertices.shape)*np.array(color_1)\n",
        "        cmap_2 = np.ones(mesh2.vertices.shape)*np.array(color_2)\n",
        "    cmap = np.concatenate([cmap_1, cmap_2], axis=0)\n",
        "    mesh = TriMesh(np.concatenate([mesh1.vertices, mesh2.vertices], axis=0),\n",
        "                   np.concatenate([mesh1.faces, mesh2.faces+mesh1.n_vertices], axis=0)).process(k=0)\n",
        "    return renderer.plot(mesh, cmap, *args, **kwargs)\n",
        "\n",
        "mesh1 = TriMesh(\"./data/Armadillo_1.off\")\n",
        "mesh2 = TriMesh(\"./data/Armadillo_2.off\")\n",
        "\n",
        "plot_superimposed(mesh1, mesh2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0iFVhrAupLB"
      },
      "outputs": [],
      "source": [
        "# VISUALIZE ICP Result\n",
        "vert1_aligned = icp_align(mesh1.vertices, mesh2.vertices, n_iter=10)\n",
        "\n",
        "plot_superimposed(TriMesh(vert1_aligned, mesh1.faces), mesh2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI414LaYupLB"
      },
      "source": [
        "## As-rigid-as possible deformation\n",
        "\n",
        "This model of  <a href=\\\"https://igl.ethz.ch/projects/ARAP/arap_web.pdf\\\">deformation</a> tries to preserves at best the shape features. As explained in the course, given a triangle mesh ($T$: triangle list, $X$: vertex positions) the goal is to find new vertex positions $Y = \\\\{ y_i\\\\}$ which are as-close-as possible to a local rotation of the initial position $X$. More precisely, we store a rotation matrix $R_i$ at each vertex $i$ and find the rotations $R$ and position $y$ minimizing\\n\",\n",
        "\n",
        "$$ \\min_{y,R} \\sum_{i} \\sum_{j \\in N_i} w_{ij} \\| y_i - y_j - R_i (x_i - x_j) \\|^2, \\text{  $y$ subject to position constraint,}$$\n",
        "\n",
        "with $w_{ij}$ the cotan-weight and $N_i$ the set of vertices adajcent to $i$.\n",
        "To solve this problem, we iterate between solving for best the position and for rotations.\n",
        "1. Finding the optimal position $y$ is a constrained Laplacian problem (just like the first question)\n",
        "$$ W y = b, \\quad \\text{where } b_i = \\sum_{j \\in N_i} \\frac{w_{ij}}{2} (R_i+R_j) (x_i - x_j) \\text{ for each vertex $i$}, $$\n",
        "and $y$ is constrained at some given vertices.\n",
        "2. Finding the optimal rotation $R_i$ amounts for solving an orthogonal Procrustes problem for each vertex $i$ where the matrix $B_i = \\sum_{j \\in N_i} w_{ij} (y_i - y_j) (x_i - x_j)^\\top$ is decomposed via a SVD (see step 3 of previous question).\n",
        "\n",
        "**To do:**\n",
        "1. Provide functions to compute the initial rotations. This is divided into two subproblems: estimating the covariance, and then computing the rotations using SVD.\n",
        "2. Fill the function to compute the right side of the optimization\n",
        "3. Write the optimization loop with the system inside. It consists of alternating between computing b with estimated positions, and solving for new positions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-P2rWBXupLB"
      },
      "source": [
        "We provide a function to compute a list of neighbors for each vertex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xD0HA-g8upLB"
      },
      "outputs": [],
      "source": [
        "def get_per_vertex_neighbors(faces):\n",
        "    \"\"\"\n",
        "    Compute per-vertex neighbors from a list of triangles\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    faces : (n, 3) array of vertex indices for each triangle\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    neighbors : list of lists of vertex indices\n",
        "    \"\"\"\n",
        "\n",
        "    neighbors = [set() for _ in range(faces.max()+1)]\n",
        "    for face in faces:\n",
        "        neighbors[face[0]].add(face[1])\n",
        "        neighbors[face[0]].add(face[2])\n",
        "\n",
        "        neighbors[face[1]].add(face[0])\n",
        "        neighbors[face[1]].add(face[2])\n",
        "\n",
        "        neighbors[face[2]].add(face[0])\n",
        "        neighbors[face[2]].add(face[1])\n",
        "\n",
        "    return [list(n) for n in neighbors]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7jBB_ySupLB"
      },
      "source": [
        "### Question 10 - Compute the covariance (Matrix B_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On utilise tout simplement la formule :\n",
        "\n",
        "$B_i = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} \\, (x_i - x_j)(x_i - x_j)^\\top$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ecXd2Ym2upLB"
      },
      "outputs": [],
      "source": [
        "def get_arap_edge_covariance(x,y, cotan_matrix, per_vertex_neighbors):\n",
        "    \"\"\"\n",
        "    Compute the covariance matrix of the edge between x and y. (Formula B_i)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x : (n,3) array of coordinates of x\n",
        "    y : (n, 3) array of coordinates of y\n",
        "    cotan_matrix : (n,n) cotan matrix of the mesh\n",
        "    per_vertex_neighbors : (n,) list with list of neighbors of each vertex\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    covariances : (n, 3, 3) covariance matrices of the edge between x and y\n",
        "    \"\"\"\n",
        "    n_vertices = len(x)\n",
        "    covariances = np.zeros((n_vertices, 3, 3))\n",
        "\n",
        "    for i in range(n_vertices):\n",
        "        for j in per_vertex_neighbors[i]:\n",
        "            w_ij = cotan_matrix[i, j]\n",
        "            diff = (x[i] - x[j]).reshape(3, 1) # pour en faire un vecteur colonne\n",
        "            covariances[i] += w_ij * (diff @ diff.T)\n",
        "\n",
        "    return covariances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xNY2slKupLB"
      },
      "source": [
        "### Question 11 - Compute Rotations from Covariance (compute R_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NMU-_IfQupLB"
      },
      "outputs": [],
      "source": [
        "def get_rot_from_covariances(covariances):\n",
        "    \"\"\"\n",
        "    Compute optimal rotation matrix from edge covariance matrices, using SVD.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    covariances : (n, 3, 3) covariance matrices for each vertex\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    rots : (n, 3, 3) rotation matrices for each vertex\n",
        "    \"\"\"\n",
        "    rots = np.zeros_like(covariances)\n",
        "\n",
        "    for i in range(len(covariances)):\n",
        "        U, S, Vt = np.linalg.svd(covariances[i])\n",
        "        #même chose que pour la rigid transform\n",
        "        R = Vt.T @ U.T\n",
        "        if np.linalg.det(R) < 0:\n",
        "            Vt[-1, :] *= -1\n",
        "            R = Vt.T @ U.T\n",
        "        rots[i] = R\n",
        "\n",
        "    return rots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB1zlU8HupLC"
      },
      "source": [
        "### Question 12 - Compute Rotated vertices (vector b_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeNBtmGdupLC"
      },
      "outputs": [],
      "source": [
        "def compute_ARAP_rotated_vert(vertices, rotations, cotan_matrix, per_vertex_neighbors):\n",
        "    \"\"\"\n",
        "    Compute the right hand term of the ARAP linear system (formula b_i)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    vertices : (n, 3) array of vertices\n",
        "    rotations : (n, 3, 3) array of rotation matrices\n",
        "    cotan_matrix : (n,n) cotan matrix of the mesh\n",
        "    per_vertex_neighbors : (n,) list with list of neighbors of each vertex\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    b : (n, 3) right hand term of the ARAP linear system\n",
        "    \"\"\"\n",
        "\n",
        "    b = np.zeros((len(vertices), 3))\n",
        "    for i in range(len(vertices)):\n",
        "        for j in per_vertex_neighbors[i]:\n",
        "            w_ij = cotan_matrix[i, j]\n",
        "            diff = (vertices[i] - vertices[j])\n",
        "            b[i] += w_ij / 2 * (rotations[i] + rotations[j]) @ diff\n",
        "\n",
        "    return b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7qLN7jvupLC"
      },
      "source": [
        "### Question 13 - Apply ARAP Deformation.\n",
        "\n",
        "We first load the mesh and visualize it with the objective landmark deformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fja6OpefupLC"
      },
      "outputs": [],
      "source": [
        "mesh3 = TriMesh(\"data/cactus.off\").process(k=0)\n",
        "\n",
        "# THE ID OF THE LANDMARKS\n",
        "id_mouv = [1756, 1298, 1663, 118, 637, 1842]\n",
        "id_lock = id_mouv\n",
        "# THE EXPECTED POSITIONS OF THE LANDMARKS AFTER OPTIMIZATION\n",
        "disp = np.array([[0,-0.25,-0.46], [0,-0.4,-0.3], [0,-0.55, -0.], [0, -0.08, -0.05], [0, -0.08, -0.05], [0, 0, 0]])\n",
        "positions_target = mesh3.vertices[id_lock] + disp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WocLytiupLC"
      },
      "outputs": [],
      "source": [
        "np.tile(np.arange(len(id_lock)),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlUL1BhbupLC"
      },
      "outputs": [],
      "source": [
        "# VISUALIZE THE LANDMARKS\n",
        "renderer.plot(mesh3,\n",
        "         points=np.concatenate([mesh3.vertices[id_lock], positions_target]),\n",
        "         cmap_p=np.tile(np.arange(len(id_lock)),2),\n",
        "         colormap='jet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzAG7ALMupLC"
      },
      "source": [
        "### ARAP Loop\n",
        "\n",
        "Write the ARAP loop by filling in the blanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zhJBXM1AupLC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'mesh3' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vertex_neighbors \u001b[38;5;241m=\u001b[39m get_per_vertex_neighbors(\u001b[43mmesh3\u001b[49m\u001b[38;5;241m.\u001b[39mfaces)\n\u001b[0;32m      2\u001b[0m n_arap_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m W \u001b[38;5;241m=\u001b[39m mesh3\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mcopy()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'mesh3' is not defined"
          ]
        }
      ],
      "source": [
        "vertex_neighbors = get_per_vertex_neighbors(mesh3.faces)\n",
        "n_arap_loop = 5\n",
        "W = mesh3.W.copy()\n",
        "print(W.shape, mesh3.n_vertices)\n",
        "# Interior vertices\n",
        "id_in = [i for i in range(mesh3.n_vertices) if i not in id_lock]\n",
        "\n",
        "\n",
        "W_sparse = scipy.sparse.csr_matrix(W)              \n",
        "L = scipy.sparse.diags(W_sparse.sum(axis=1).A1) - W_sparse \n",
        "\n",
        "# Initial guess for the vertices\n",
        "init_res = np.zeros_like(mesh3.vertices)\n",
        "init_res[id_lock] = mesh3.vertices[id_lock] # positions des sommets verrouillés\n",
        "for i in range(5):\n",
        "\n",
        "    # Compute rotation matrices\n",
        "    covariances = get_arap_edge_covariance(mesh3.vertices, init_res, W, vertex_neighbors)\n",
        "    rotations = get_rot_from_covariances(covariances)\n",
        "    b_term = compute_ARAP_rotated_vert(mesh3.vertices, rotations, W, vertex_neighbors)\n",
        "\n",
        "\n",
        "    # Compute right hand term and left hand term of ARAP SYSTEM\n",
        "    # Think about the constraint, go back the the text in part 1.1 to see how to build the constrained system\n",
        "\n",
        "    lhs = W.tocsr()\n",
        "    lhs_in = lhs[id_in, :][:, id_in]\n",
        "    rhs = b_term[id_in]\n",
        "\n",
        "    res = scipy.sparse.linalg.spsolve(lhs, rhs)\n",
        "\n",
        "    ## Add the update of your guess\n",
        "    \n",
        "    init_res[id_in] = res\n",
        "\n",
        "final_res = init_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxAbf-ByupLC"
      },
      "outputs": [],
      "source": [
        "last_mesh = TriMesh(final_res, mesh3.faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9x4qsQJupLC"
      },
      "outputs": [],
      "source": [
        "plot_superimposed(last_mesh, mesh3,\n",
        "         points=np.concatenate([mesh3.vertices[id_lock], positions_target]),\n",
        "         cmap_p=np.tile(np.arange(len(id_lock)),2), point_size=0.01,\n",
        "         colormap='jet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKL7ZzXYupLC"
      },
      "source": [
        "### Question 15: Write a non-rigid registration algorithm\n",
        "\n",
        "Now that you have a non-rigid deformation model, make a non-rigid icp function such that it does:\n",
        "\n",
        "1. Compute approximate spatial nearest neighbor\n",
        "2. Use this as a guess for ARAP and compute ARAP deformation\n",
        "3. Updates the approximate spatial guess\n",
        "\n",
        "Finally, plot the registration. All main functions are ready, it's time to write a bit on your own."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "graphprocess (3.10.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
